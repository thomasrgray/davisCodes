import pymc3 as pm
import numpy as np
import matplotlib.pyplot as plt

# Sample data (replace with your actual data)
data_condition1 = np.array([0,
0,
0,
4,
1,
7,
11,
4,
7,
22,
7,
5,
0,
4,
14,
15,
19,
14,
8,
2,
0,
17,
4,
7,
2,
20,
0,
5,
39,
8,
6,
1,
29,
39,
39,
41,
40,
41,
41,
39,
33,
40,
37,
31,
33,
0,
35,
0,
0,
0,
37,
35,
35,
0,
38,
38,
29,
0,
33,
0,
0,
0,
17,
0,
26,
37,
39,
37,
40,
40,
42,
40,
42,
43,
43,
40,
42,
43,
43,
43,
43,
43,
42,
41,
0,
32,
40,
0,
41,
4])
data_condition2 = np.array([0,
34,
37,
9,
5,
27,
19,
25,
13,
6,
17,
29,
17,
13,
28,
16,
18,
0,
16,
0,
0,
0,
0,
0,
40,
0,
10,
0,
0,
0,
38,
35,
37,
37,
37,
39,
38,
39,
36,
36,
37,
39,
33,
3,
35,
0,
0,
0,
0,
0,
0,
0,
0,
6,
37,
35,
0,
0,
38,
0,
41,
37,
42,
41,
39,
39,
43,
19,
42,
41,
39,
38,
44,
44,
37,
41,
42,
0,
42,
39,
42,
0,
43,
36,
42,
42,
37,
41,
42,
0])


# Combine data from all conditions
data = np.concatenate([data_condition1, data_condition2])

# Define the number of trials in each condition
n_condition1 = len(data_condition1)
n_condition2 = len(data_condition2)

# Define a prior distribution for the common mean (you can adjust this as needed)
mu_prior = 10
sigma_prior = 5

# Create a Bayesian model
with pm.Model() as model:
    # Prior distribution for the common mean
    mean = pm.Normal('mean', mu=mu_prior, sigma=sigma_prior)
    
    # Likelihood for each condition
    likelihood_condition1 = pm.Poisson('likelihood_condition1', mu=mean, observed=data_condition1)
    likelihood_condition2 = pm.Poisson('likelihood_condition2', mu=mean, observed=data_condition2)

# Perform Bayesian inference
with model:
    trace = pm.sample(2000, tune=1000)

# Plot the posterior distribution of the common mean
pm.plot_posterior(trace, var_names=['mean'], credible_interval=0.95, kind='hist')
plt.title('Posterior Distribution of Common Mean')
plt.xlabel('Mean Licks per Trial')
plt.ylabel('Density')
plt.show()
